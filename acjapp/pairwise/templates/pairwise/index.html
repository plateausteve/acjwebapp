{% extends "pairwise/base.html" %}

{% block content %}
    <h1>About</h1>
    <p>This ACJ web app collects comparative judgment data that can be analyzed with Thurstone's law of comparative judgment (CJ), which is related to Rasch modeling and Item Response Theory in modern day psychometrics. Comparative Judgment is a measurement tool for estimating an unknown paramater attribute for a group of items from the perspective of one or more judges. The parameter investigated with this method should be a holistic attribute all items share to varying degrees.</p>
    <p>The value of collecting and crunching comparatice judgment data comes from the resulting information about:</p>
    <ul>
        <li>The perception of the <b>judge(s)</b>, and</li>
        <li>An estimated measure of a <b>parameter</b>, quality, or characteristic of the items being compared.</li>
    </ul>
    <h4>Users</h4>
    <p>Users of the app are educators who assess other educators' students' work, upload thier own students' work for other educators to assess, or both. Users agree to the Terms of Use and Assessment Privacy Policy protecting personal information. </p>
    <h4>Terminology</h4>
    <ul>
        <li><dfn>Set</dfn> is the collection of items being compared.</li>
        <li><dfn>Script</dfn> is the term used in early research literature for an item being compared.</li>
        <li><dfn>Score</dfn> is the estimated parameter value of item after comparison.</li>
        <li><dfn>Judge</dfn> is the person doing pairwise comparisons.</li>
        <li><dfn>Student ID</dfn> is the anonymous ID code that links an item to the person who created it.</li>
    </ul>
    <h4>Making comparisons</h4>
    <p>Users who are judges have been assigned one or more sets of anonymous scripts. Select a set from the <b>Compare</b> menu, where two scripts will be presented side-by-side. Using your own criteria, decide whether the left or right is more ______. (The page will prompt you with the comparison term for that set.) Make sure to view all pages of each PDF file before making a judgement.</p>
    <p>Keep making comparisons until you reach the limit when you'll no longer be presented with pairs from that set. As you progress, you will be show pairs that are more and more similar. Use the criteria you've developed for your decisions, but don't overthink your decisions or worry about making the wrong decisions. There will be plenty of them to account for ambiguity.</p>
    <h4>Checking your comparisons</h4>
    <p>Select a set from the <b>Comparisons</b> menu to see a table of all comparisons you've made so far. Clicking on the script ID code will let you inspect each one.</p>
    <h4>Checking your results</h4>
    <p>Select a set from the <b>My Results</b> menu to see dynamically computed statistics based on the comparisons you've made. The purpose of this table is to show your progress as you make comparisons. The reliability and validity of these rankings and statistics are not sufficient for educational decisionmaking.</p>
    <h4>Viewing combined ranks and scores</h4>
    <p>Select a set from the <b>Group Results</b> menu to see how ranks and scores are estimated combining the comparisons of up to three judges. When the similarity of the rank order of scripts by three judges reaches acceptable levels, the scores will be finalized.<br>
{% endblock %}